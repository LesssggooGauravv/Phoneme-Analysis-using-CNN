{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01d2be3-e523-4c33-ade1-461fe212030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial version\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## 1. Parameters and Setup\n",
    "BASE_DIR = 'phonemes'  # Script ke saath waala folder\n",
    "SR = 22050\n",
    "N_MELS = 128\n",
    "\n",
    "# --- YEH HAI KEY ---\n",
    "# Har phoneme file ke 100 version banayenge\n",
    "AUGMENTATION_FACTOR = 100 \n",
    "\n",
    "# Training Parameters\n",
    "EPOCHS = 25         # Max epochs (Early Stopping use karenge)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "## 2. Helper Functions (Aapke puraane code se)\n",
    "\n",
    "def extract_mel_spectrogram(y, sr=SR, n_mels=N_MELS):\n",
    "    \"\"\"Audio (y) ko Mel Spectrogram (dB) mein convert karta hai.\"\"\"\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "    return mel_db\n",
    "\n",
    "def augment_audio(y, sr=SR):\n",
    "    \"\"\"Audio (y) par randomly ek audio-level augmentation apply karta hai.\"\"\"\n",
    "    # 'none' ko hata diya taaki har copy thodi alag ho\n",
    "    choice = np.random.choice(['pitch', 'stretch', 'noise'])\n",
    "    \n",
    "    if choice == 'pitch':\n",
    "        y = librosa.effects.pitch_shift(y, sr=sr, n_steps=np.random.uniform(-1, 1))\n",
    "    elif choice == 'stretch':\n",
    "        rate = np.random.uniform(0.9, 1.1)\n",
    "        y = librosa.effects.time_stretch(y, rate=rate)\n",
    "    elif choice == 'noise':\n",
    "        y = y + 0.003 * np.random.randn(len(y))\n",
    "    return y\n",
    "\n",
    "def spec_augment(mel_spectrogram, time_mask_max=40, freq_mask_max=12):\n",
    "    \"\"\"Spectrogram (image) par Time aur Frequency masking apply karta hai.\"\"\"\n",
    "    mel_spec_aug = mel_spectrogram.copy()\n",
    "    freq_dim, time_dim = mel_spec_aug.shape\n",
    "    \n",
    "    # Freq Mask\n",
    "    freq_mask_num = np.random.randint(0, freq_mask_max)\n",
    "    f_zero = np.random.randint(0, freq_dim - freq_mask_num)\n",
    "    mel_spec_aug[f_zero:f_zero + freq_mask_num, :] = np.mean(mel_spec_aug)\n",
    "\n",
    "    # Time Mask\n",
    "    time_mask_num = np.random.randint(0, time_mask_max)\n",
    "    t_zero = np.random.randint(0, time_dim - time_mask_num)\n",
    "    mel_spec_aug[:, t_zero:t_zero + time_mask_num] = np.mean(mel_spec_aug)\n",
    "    \n",
    "    return mel_spec_aug\n",
    "\n",
    "## 3. Data Loading and MASSIVE Augmentation\n",
    "print(\"Starting data loading and augmentation...\")\n",
    "\n",
    "X, y = [], []\n",
    "original_files = [] # Prediction ke liye original files save karenge\n",
    "\n",
    "try:\n",
    "    # os.walk aapke saare subfolders (nasal, fricatives...) mein jaayega\n",
    "    for root, dirs, files in os.walk(BASE_DIR):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # --- YEH HAI AAPKA LABEL ---\n",
    "                # Filename (e.g., \"Î¸.wav\") se \".wav\" hataya\n",
    "                label = file.split('.')[0]\n",
    "                \n",
    "                try:\n",
    "                    # Original audio ko ek baar load karo\n",
    "                    y_raw, sr_load = librosa.load(file_path, sr=SR)\n",
    "                    \n",
    "                    # Original file ko prediction test ke liye save karo\n",
    "                    original_files.append((file_path, label))\n",
    "\n",
    "                    # --- Augmentation Loop ---\n",
    "                    for i in range(AUGMENTATION_FACTOR):\n",
    "                        # 1. Audio Augmentation\n",
    "                        y_aug = augment_audio(y_raw, SR)\n",
    "                        \n",
    "                        # 2. Feature Extraction\n",
    "                        mel_db = extract_mel_spectrogram(y_aug, sr=SR, n_mels=N_MELS)\n",
    "                        \n",
    "                        # 3. Spectrogram Augmentation\n",
    "                        mel_spec_aug = spec_augment(mel_db)\n",
    "                        \n",
    "                        X.append(mel_spec_aug)\n",
    "                        y.append(label)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "    print(f\"Data processing complete. Total samples created: {len(X)}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    ## 4. Padding (Sabko same size karna)\n",
    "    print(\"Padding spectrograms to uniform length...\")\n",
    "    max_length = max(mel.shape[1] for mel in X)\n",
    "    print(f\"Maximum spectrogram length: {max_length}\")\n",
    "\n",
    "    X_padded = []\n",
    "    for mel in X:\n",
    "        pad_width = ((0, 0), (0, max_length - mel.shape[1]))\n",
    "        padded_mel = np.pad(mel, pad_width=pad_width, mode='constant', constant_values=np.min(mel))\n",
    "        X_padded.append(padded_mel)\n",
    "\n",
    "    X = np.array(X_padded)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Channel dimension add karo (Model ke liye)\n",
    "    X = X[..., np.newaxis]\n",
    "\n",
    "    print(f\"Final shape of X (features): {X.shape}\")\n",
    "    print(f\"Final shape of y (labels): {y.shape}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    ## 5. Encoding & Splitting\n",
    "    print(\"Encoding labels and splitting data...\")\n",
    "    \n",
    "    # LabelEncoder 'Î¸', 'tÊƒ' jaise text labels ko 0, 1, 2...43 mein badal dega\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    num_classes = len(le.classes_)\n",
    "    \n",
    "    print(f\"Total classes found: {num_classes}\")\n",
    "    # print(le.classes_) # Saare 44 phonemes print karega\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_encoded, \n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        stratify=y_encoded # Har phoneme ke samples train/test mein barabar baanto\n",
    "    )\n",
    "    print(f\"Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    ## 6. Build the 2D-CNN Model\n",
    "    input_shape = X_train.shape[1:]  # (N_MELS, max_length, 1)\n",
    "\n",
    "    print(f\"Building model for {num_classes} classes...\")\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        # --- YEH KEY CHANGE HAI ---\n",
    "        # Ab yeh 44 output dega\n",
    "        layers.Dense(num_classes, activation='softmax') \n",
    "    ])\n",
    "\n",
    "    ## 7. Compile & Train\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy', # 0-43 labels ke liye perfect\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.summary()\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    print(\"\\nStarting model training...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "    print(\"Training complete.\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    ## 8. Evaluate\n",
    "    print(\"Evaluating model performance...\")\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"âœ… Final Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    ## 9. Prediction Test (Recognition)\n",
    "    print(\"Running prediction test on ORIGINAL files...\")\n",
    "    \n",
    "    # Model ko test karne ke liye, original files mein se random 5 chuno\n",
    "    random.shuffle(original_files)\n",
    "    \n",
    "    for file_path, true_label in original_files[:5]:\n",
    "        # 1. Original file ko load karo (bina augmentation)\n",
    "        y_raw, sr = librosa.load(file_path, sr=SR)\n",
    "        \n",
    "        # 2. Features nikaalo\n",
    "        mel_db = extract_mel_spectrogram(y_raw, sr=SR, n_mels=N_MELS)\n",
    "        \n",
    "        # 3. Pad karo (Training waali max_length tak)\n",
    "        pad_width = ((0, 0), (0, max_length - mel_db.shape[1]))\n",
    "        mel_padded = np.pad(mel_db, pad_width, mode='constant', constant_values=np.min(mel_db))\n",
    "        \n",
    "        # 4. Model ke liye shape ready karo (Batch, H, W, Channel)\n",
    "        mel_ready = mel_padded[np.newaxis, ..., np.newaxis]\n",
    "        \n",
    "        # 5. Predict karo\n",
    "        prediction_probs = model.predict(mel_ready)\n",
    "        predicted_index = np.argmax(prediction_probs)\n",
    "        predicted_label = le.inverse_transform([predicted_index])[0]\n",
    "        \n",
    "        print(f\"\\nFile: {file}\")\n",
    "        print(f\"ðŸŽ¯ True Phoneme: '{true_label}'\")\n",
    "        print(f\"ðŸ”¥ Predicted Phoneme: '{predicted_label}'\")\n",
    "        if true_label == predicted_label:\n",
    "            print(\"Result: CORRECT! ðŸŽ‰\")\n",
    "        else:\n",
    "            print(\"Result: WRONG. ðŸ‘Ž\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ek bada error aa gaya: {e}\")\n",
    "    print(\"Check karo ki 'phonemes' folder script ke paas hai ya nahi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f5a70c-960b-40a2-b2f4-82cc8d11c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# PHONEME CLASSIFICATION â€“ PURE CNN (STABLE & FINAL VERSION)\n",
    "# =================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# -------------------------------------------------\n",
    "# REPRODUCIBILITY\n",
    "# -------------------------------------------------\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# PARAMETERS\n",
    "# -------------------------------------------------\n",
    "\n",
    "BASE_DIR = \"phonemes\"\n",
    "SR = 22050\n",
    "N_MELS = 128\n",
    "TARGET_SAMPLES_PER_PHONEME = 100\n",
    "\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 32\n",
    "PATIENCE = 6\n",
    "LR = 3e-4\n",
    "\n",
    "# -------------------------------------------------\n",
    "# FEATURE EXTRACTION\n",
    "# -------------------------------------------------\n",
    "\n",
    "def extract_features(y, sr=SR):\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=y, sr=sr, n_mels=N_MELS, power=2.0\n",
    "    )\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "    d1 = librosa.feature.delta(mel_db)\n",
    "    d2 = librosa.feature.delta(mel_db, order=2)\n",
    "\n",
    "    return np.stack([mel_db, d1, d2], axis=-1)  # (128, T, 3)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# AUGMENTATION\n",
    "# -------------------------------------------------\n",
    "\n",
    "AUGS = [\"none\", \"pitch_up\", \"pitch_down\", \"stretch_fast\", \"stretch_slow\"]\n",
    "\n",
    "def apply_aug(y, aug):\n",
    "    if aug == \"none\":\n",
    "        return y\n",
    "    if aug == \"pitch_up\":\n",
    "        return librosa.effects.pitch_shift(y=y, sr=SR, n_steps=2)\n",
    "    if aug == \"pitch_down\":\n",
    "        return librosa.effects.pitch_shift(y=y, sr=SR, n_steps=-2)\n",
    "    if aug == \"stretch_fast\":\n",
    "        y2 = librosa.effects.time_stretch(y=y, rate=1.1)\n",
    "        return librosa.util.fix_length(y2, size=len(y))\n",
    "    if aug == \"stretch_slow\":\n",
    "        y2 = librosa.effects.time_stretch(y=y, rate=0.9)\n",
    "        return librosa.util.fix_length(y2, size=len(y))\n",
    "    return y\n",
    "\n",
    "# -------------------------------------------------\n",
    "# DATASET CREATION\n",
    "# -------------------------------------------------\n",
    "\n",
    "X_list, y_list = [], []\n",
    "\n",
    "phoneme_dirs = sorted([\n",
    "    d for d in os.listdir(BASE_DIR)\n",
    "    if os.path.isdir(os.path.join(BASE_DIR, d))\n",
    "])\n",
    "\n",
    "for phoneme in phoneme_dirs:\n",
    "    files = [\n",
    "        f for f in os.listdir(os.path.join(BASE_DIR, phoneme))\n",
    "        if f.endswith(\".wav\")\n",
    "    ]\n",
    "\n",
    "    idx = 0\n",
    "    while idx < TARGET_SAMPLES_PER_PHONEME:\n",
    "        f = files[idx % len(files)]\n",
    "        aug = AUGS[idx % len(AUGS)]\n",
    "\n",
    "        y, _ = librosa.load(\n",
    "            os.path.join(BASE_DIR, phoneme, f), sr=SR\n",
    "        )\n",
    "\n",
    "        feat = extract_features(apply_aug(y, aug))\n",
    "        X_list.append(feat)\n",
    "        y_list.append(phoneme)\n",
    "        idx += 1\n",
    "\n",
    "    print(f\"{phoneme}: {TARGET_SAMPLES_PER_PHONEME} samples\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# PADDING\n",
    "# -------------------------------------------------\n",
    "\n",
    "max_len = max(x.shape[1] for x in X_list)\n",
    "\n",
    "X = np.array([\n",
    "    np.pad(x, ((0,0),(0, max_len - x.shape[1]),(0,0)), mode=\"constant\")\n",
    "    for x in X_list\n",
    "], dtype=np.float32)\n",
    "\n",
    "y = np.array(y_list)\n",
    "\n",
    "print(\"Final X shape:\", X.shape)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# NORMALIZATION (CRITICAL FOR SMOOTH CURVES)\n",
    "# -------------------------------------------------\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_flat = X.reshape(-1, X.shape[-1])\n",
    "X_flat = scaler.fit_transform(X_flat)\n",
    "X = X_flat.reshape(X.shape)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# LABEL ENCODING + SPLIT\n",
    "# -------------------------------------------------\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_enc,\n",
    "    test_size=0.2,\n",
    "    stratify=y_enc,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# MODEL â€“ STABLE CNN\n",
    "# -------------------------------------------------\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=X_train.shape[1:]),\n",
    "\n",
    "    layers.Conv2D(32, 3, padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(\"relu\"),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(64, 3, padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(\"relu\"),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(96, 3, padding=\"same\"),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(\"relu\"),\n",
    "\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(len(le.classes_), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(LR),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# TRAINING\n",
    "# -------------------------------------------------\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=PATIENCE, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(patience=3, factor=0.5, verbose=1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# EVALUATION\n",
    "# -------------------------------------------------\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"-\"*30)\n",
    "print(\"Evaluating model performance...\")\n",
    "final_loss, final_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"âœ… Final Test Accuracy: {final_acc*100:.2f}%\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# TRAINING CURVES\n",
    "# -------------------------------------------------\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend([\"Train\",\"Val\"])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend([\"Train\",\"Val\"])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# PREDICTION TEST ON ORIGINAL FILES\n",
    "# -------------------------------------------------\n",
    "\n",
    "print(\"\\nRunning prediction test on ORIGINAL files...\")\n",
    "\n",
    "def predict_file(filepath):\n",
    "    y, _ = librosa.load(filepath, sr=SR)\n",
    "    feat = extract_features(y)\n",
    "\n",
    "    feat = np.pad(\n",
    "        feat,\n",
    "        ((0,0),(0, max_len - feat.shape[1]),(0,0)),\n",
    "        mode=\"constant\"\n",
    "    )\n",
    "\n",
    "    # normalize using TRAIN scaler\n",
    "    feat_flat = feat.reshape(-1, feat.shape[-1])\n",
    "    feat_flat = scaler.transform(feat_flat)\n",
    "    feat = feat_flat.reshape(1, *feat.shape)\n",
    "\n",
    "    probs = model.predict(feat)\n",
    "    pred_idx = np.argmax(probs)\n",
    "    return le.inverse_transform([pred_idx])[0]\n",
    "\n",
    "\n",
    "# pick ONE original file per phoneme (clean, no augmentation)\n",
    "for phoneme in phoneme_dirs:\n",
    "    phoneme_path = os.path.join(BASE_DIR, phoneme)\n",
    "    files = [f for f in os.listdir(phoneme_path) if f.endswith(\".wav\")]\n",
    "    if not files:\n",
    "        continue\n",
    "\n",
    "    test_file = files[0]  # just one clean file\n",
    "    file_path = os.path.join(phoneme_path, test_file)\n",
    "\n",
    "    predicted = predict_file(file_path)\n",
    "\n",
    "    print(f\"\\nFile: {test_file}\")\n",
    "    print(f\"ðŸŽ¯ True Phoneme: '{phoneme}'\")\n",
    "    print(f\"ðŸ”¥ Predicted Phoneme: '{predicted}'\")\n",
    "\n",
    "    if predicted == phoneme:\n",
    "        print(\"Result: CORRECT! ðŸŽ‰\")\n",
    "    else:\n",
    "        print(\"Result: WRONG âŒ\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce543ef1-b288-43b6-9503-121ca5a494a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## 1. Parameters\n",
    "BASE_DIR = 'phonemes'  # Aapka 'phonemes' folder\n",
    "SR = 22050             # Sample Rate\n",
    "N_MELS = 128           # Mel Spectrogram height\n",
    "\n",
    "# Categories jinhe aap compare karna chahte hain\n",
    "# Yahi aapke subfolder names hone chahiye\n",
    "PHONEME_CATEGORIES = [\n",
    "    'plosives',\n",
    "    'nasals',\n",
    "    'affricates',\n",
    "    'fricatives',\n",
    "    'approximants',\n",
    "    'diphthongs',\n",
    "    'monophthongs'\n",
    "]\n",
    "\n",
    "## 2. Helper Function (Spectrogram extraction)\n",
    "def extract_mel_spectrogram(file_path, sr=SR, n_mels=N_MELS):\n",
    "    \"\"\"\n",
    "    Ek audio file se Mel Spectrogram extract karta hai.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y, sr_load = librosa.load(file_path, sr=sr)\n",
    "        mel = librosa.feature.melspectrogram(y=y, sr=sr_load, n_mels=n_mels)\n",
    "        mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "        return mel_db, y, sr_load\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or processing {file_path}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "## 3. Main Logic: Collect, Process, Plot\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    selected_phonemes = {} # Dictionary to store chosen file_path and label for each category\n",
    "\n",
    "    print(\"Collecting a random phoneme from each category...\")\n",
    "    for category in PHONEME_CATEGORIES:\n",
    "        category_path = os.path.join(BASE_DIR, category)\n",
    "        \n",
    "        if not os.path.exists(category_path):\n",
    "            print(f\"Warning: Category folder '{category_path}' not found. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        # Saari .wav files collect karo us category mein se\n",
    "        wav_files = [f for f in os.listdir(category_path) if f.endswith('.wav')]\n",
    "        \n",
    "        if not wav_files:\n",
    "            print(f\"Warning: No .wav files found in '{category_path}'. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        # Ek random file chuno\n",
    "        chosen_file = random.choice(wav_files)\n",
    "        file_path = os.path.join(category_path, chosen_file)\n",
    "        \n",
    "        # Phoneme label (file name bina .wav ke)\n",
    "        phoneme_label = chosen_file.replace('.wav', '')\n",
    "        \n",
    "        selected_phonemes[category] = {'path': file_path, 'label': phoneme_label}\n",
    "        print(f\"  - {category.capitalize()}: Selected '{phoneme_label}' from {file_path}\")\n",
    "\n",
    "    if not selected_phonemes:\n",
    "        print(\"\\nNo phonemes selected for plotting. Please check folder structure and file types.\")\n",
    "    else:\n",
    "        # Plotting setup\n",
    "        num_plots = len(selected_phonemes)\n",
    "        # 2 columns mein arrange karenge, rows uske hisaab se\n",
    "        num_cols = 2\n",
    "        num_rows = (num_plots + num_cols - 1) // num_cols # Ceiling division\n",
    "\n",
    "        plt.figure(figsize=(15, 5 * num_rows)) # Overall figure size\n",
    "\n",
    "        plot_idx = 1\n",
    "        for category, info in selected_phonemes.items():\n",
    "            file_path = info['path']\n",
    "            phoneme_label = info['label']\n",
    "            \n",
    "            mel_db, y_audio, sr_audio = extract_mel_spectrogram(file_path)\n",
    "            \n",
    "            if mel_db is None:\n",
    "                continue\n",
    "\n",
    "            plt.subplot(num_rows, num_cols, plot_idx)\n",
    "            \n",
    "            # Librosa display function use karenge\n",
    "            librosa.display.specshow(mel_db, \n",
    "                                     sr=sr_audio, \n",
    "                                     x_axis='time', \n",
    "                                     y_axis='mel', \n",
    "                                     cmap='viridis') # 'viridis' ya 'magma' achha dikhta hai\n",
    "            \n",
    "            plt.colorbar(format='%+2.0f dB')\n",
    "            plt.title(f\"{category.capitalize()}: /{phoneme_label}/ Spectrogram\", fontsize=14)\n",
    "            plt.tight_layout() # Plots ke beech space maintain karta hai\n",
    "            \n",
    "            plot_idx += 1\n",
    "        \n",
    "        plt.suptitle(\"Comparison of Phoneme Category Spectrograms\", fontsize=16, y=1.02)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dd6df7-c321-425b-8789-63932e1dbe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized confusion matrix\n",
    "cm_norm = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
    "sns.heatmap(cm_norm, annot=True, cmap=\"Blues\",\n",
    "            xticklabels=le.classes_,\n",
    "            yticklabels=le.classes_)\n",
    "plt.title(\"Normalized Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
